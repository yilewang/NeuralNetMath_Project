{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Math Project Notebook\n",
    "\n",
    "This is a notebook for supervised machine learning project in Neural Network Mathematics class. \n",
    "\n",
    "Group members: Luke, Akshay, Yile\n",
    "\n",
    "#### variable names explanation:\n",
    "| Var name | Feature name | Description|\n",
    "|---|---|---|\n",
    "|pos      | Num posts    | Number of total posts that the user has ever posted.|\n",
    "|flg      | Num following | Number of following|\n",
    "|flr      | Num followers | Number of followers|\n",
    "|bl | Biography length | Length (number of characters) of the user's biography|\n",
    "|pic | Picture availability | Value 0 if the user has no profile picture, or 1 if has|\n",
    "|lin | Link availability | Value 0 if the user has no external URL, or 1 if has|\n",
    "|cl | Average caption length | The average number of character of captions in media|\n",
    "|cz | Caption zero | Percentage (0.0 to 1.0) of captions that has almost zero (<=3) length|\n",
    "|ni | Non image percentage | Percentage (0.0 to 1.0) of non-image media. There are three types of media on an Instagram post, i.e. image, video, carousel|\n",
    "|erl | Engagement rate (Like) | Engagement rate (ER) is commonly defined as (num likes) divide by (num media) divide by (num followers)|\n",
    "|erc | Engagement rate (Comm.) | Similar to ER like, but it is for comments|\n",
    "|lt | Location tag percentage | Percentage (0.0 to 1.0) of posts tagged with location|\n",
    "|hc | Average hashtag count | Average number of hashtags used in a post|\n",
    "|pr | Promotional keywords | Average use of promotional keywords in hashtag, i.e. {regrann, contest, repost, giveaway, mention, share, give away, quiz}|\n",
    "|fo | Followers keywords | Average use of followers hunter keywords in hashtag, i.e. {follow, like, folback, follback, f4f}|\n",
    "|cs | Cosine similarity | Average cosine similarity of between all pair of two posts a user has|\n",
    "|pi | Post interval | Average interval between posts (in hours)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic probability model is\n",
    "\n",
    "$ \\hat{p}(s, \\theta) = [1 + e^{-\\hat{y}(s, \\theta)}]^{-1} $\n",
    "\n",
    "The $\\hat{y}$ is defined as:\n",
    "\n",
    "$ \\hat{y}(s, \\theta) = \\theta^T [s^T 1]^T  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function is defined as\n",
    "\n",
    "$ c([y,s], \\theta) = - y  log\\hat{p}(s, \\theta) - (1-y)log(1-\\hat{p}(s, \\theta)) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function is\n",
    "\n",
    "$ l_{n}(\\theta) = -(1/n)\\sum_{i=1}^{n} c([y,s], \\theta) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent process is\n",
    "\n",
    "$ \\frac{dc_{i}}{d\\theta} = -(y_i - \\hat{y}_i) [s_i^{T}, 1] $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>flw</th>\n",
       "      <th>flg</th>\n",
       "      <th>bl</th>\n",
       "      <th>pic</th>\n",
       "      <th>lin</th>\n",
       "      <th>cl</th>\n",
       "      <th>cz</th>\n",
       "      <th>ni</th>\n",
       "      <th>erl</th>\n",
       "      <th>erc</th>\n",
       "      <th>lt</th>\n",
       "      <th>hc</th>\n",
       "      <th>pr</th>\n",
       "      <th>fo</th>\n",
       "      <th>cs</th>\n",
       "      <th>pi</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>325</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.094985</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "      <td>321</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14.390000</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.206826</td>\n",
       "      <td>230.412857</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>970</td>\n",
       "      <td>308</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.572174</td>\n",
       "      <td>43.569939</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>86</td>\n",
       "      <td>360</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.859799</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>285</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.290000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.300494</td>\n",
       "      <td>0.126019</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65321</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.270000</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>1745.291260</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65322</th>\n",
       "      <td>652</td>\n",
       "      <td>3000</td>\n",
       "      <td>1300</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389</td>\n",
       "      <td>8.520000</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.169917</td>\n",
       "      <td>54.629120</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65323</th>\n",
       "      <td>1500</td>\n",
       "      <td>3700</td>\n",
       "      <td>3200</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>9.390000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.058908</td>\n",
       "      <td>129.802048</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65324</th>\n",
       "      <td>329</td>\n",
       "      <td>1500</td>\n",
       "      <td>1800</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>290</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.103174</td>\n",
       "      <td>53.402840</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65325</th>\n",
       "      <td>206</td>\n",
       "      <td>659</td>\n",
       "      <td>608</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>25.549999</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>604.981445</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65326 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pos   flw   flg   bl  pic  lin   cl        cz     ni        erl   erc  \\\n",
       "0        44    48   325   33    1    0   12  0.000000  0.000   0.000000  0.00   \n",
       "1        10    66   321  150    1    0  213  0.000000  1.000  14.390000  1.97   \n",
       "2        33   970   308  101    1    1  436  0.000000  1.000  10.100000  0.30   \n",
       "3        70    86   360   14    1    0    0  1.000000  0.000   0.780000  0.06   \n",
       "4         3    21   285   73    1    0   93  0.000000  0.000  14.290000  0.00   \n",
       "...     ...   ...   ...  ...  ...  ...  ...       ...    ...        ...   ...   \n",
       "65321    13   145   642    0    1    0    7  0.461538  0.000  14.270000  0.58   \n",
       "65322   652  3000  1300  146    1    1  384  0.000000  0.389   8.520000  0.13   \n",
       "65323  1500  3700  3200  147    1    1  129  0.000000  0.111   9.390000  0.31   \n",
       "65324   329  1500  1800  218    1    1  290  0.055556  0.000   6.350000  0.26   \n",
       "65325   206   659   608   27    1    0   77  0.000000  0.333  25.549999  0.53   \n",
       "\n",
       "          lt     hc   pr     fo        cs           pi class  \n",
       "0      0.000  0.000  0.0  0.000  0.111111     0.094985     f  \n",
       "1      0.000  1.500  0.0  0.000  0.206826   230.412857     f  \n",
       "2      0.000  2.500  0.0  0.056  0.572174    43.569939     f  \n",
       "3      0.000  0.000  0.0  0.000  1.000000     5.859799     f  \n",
       "4      0.667  0.000  0.0  0.000  0.300494     0.126019     f  \n",
       "...      ...    ...  ...    ...       ...          ...   ...  \n",
       "65321  0.000  0.077  0.0  0.000  0.192308  1745.291260     r  \n",
       "65322  0.000  1.611  0.0  0.000  0.169917    54.629120     r  \n",
       "65323  0.722  0.000  0.0  0.056  0.058908   129.802048     r  \n",
       "65324  0.222  0.500  0.0  0.000  0.103174    53.402840     r  \n",
       "65325  0.222  0.222  0.0  0.167  0.017505   604.981445     r  \n",
       "\n",
       "[65326 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "df_data = pd.read_csv(\"data/user_fake_authentic_2class.csv\")\n",
    "# training features size: 65326 x 17\n",
    "data_x = df_data.iloc[:,:-1]\n",
    "\n",
    "# label types: r=real and f=fake\n",
    "data_y = df_data.iloc[:,-1:]\n",
    "# convert to 0:fake, 1:real\n",
    "data_y = data_y.replace({'class':{\"r\": 1, \"f\":0}})\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>flw</th>\n",
       "      <th>flg</th>\n",
       "      <th>bl</th>\n",
       "      <th>pic</th>\n",
       "      <th>lin</th>\n",
       "      <th>cl</th>\n",
       "      <th>cz</th>\n",
       "      <th>ni</th>\n",
       "      <th>erl</th>\n",
       "      <th>erc</th>\n",
       "      <th>lt</th>\n",
       "      <th>hc</th>\n",
       "      <th>pr</th>\n",
       "      <th>fo</th>\n",
       "      <th>cs</th>\n",
       "      <th>pi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.132007</td>\n",
       "      <td>0.144008</td>\n",
       "      <td>0.975053</td>\n",
       "      <td>0.099005</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020912</td>\n",
       "      <td>0.138019</td>\n",
       "      <td>0.671273</td>\n",
       "      <td>0.313679</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.030092</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.481838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029645</td>\n",
       "      <td>0.871381</td>\n",
       "      <td>0.276686</td>\n",
       "      <td>0.090731</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.391672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.039140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.185676</td>\n",
       "      <td>0.228116</td>\n",
       "      <td>0.954904</td>\n",
       "      <td>0.037135</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.015543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.067827</td>\n",
       "      <td>0.920511</td>\n",
       "      <td>0.235780</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65321</th>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.077732</td>\n",
       "      <td>0.344165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.935621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65322</th>\n",
       "      <td>0.194071</td>\n",
       "      <td>0.892962</td>\n",
       "      <td>0.386950</td>\n",
       "      <td>0.043458</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.114299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.016261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65323</th>\n",
       "      <td>0.292853</td>\n",
       "      <td>0.722370</td>\n",
       "      <td>0.624752</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.025185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.025342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65324</th>\n",
       "      <td>0.137409</td>\n",
       "      <td>0.626483</td>\n",
       "      <td>0.751780</td>\n",
       "      <td>0.091049</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.121120</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.022304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65325</th>\n",
       "      <td>0.186527</td>\n",
       "      <td>0.596705</td>\n",
       "      <td>0.550526</td>\n",
       "      <td>0.024448</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.023135</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.547793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65326 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pos       flw       flg        bl       pic       lin        cl  \\\n",
       "0      0.132007  0.144008  0.975053  0.099005  0.003000  0.000000  0.036002   \n",
       "1      0.020912  0.138019  0.671273  0.313679  0.002091  0.000000  0.445424   \n",
       "2      0.029645  0.871381  0.276686  0.090731  0.000898  0.000898  0.391672   \n",
       "3      0.185676  0.228116  0.954904  0.037135  0.002653  0.000000  0.000000   \n",
       "4      0.009690  0.067827  0.920511  0.235780  0.003230  0.000000  0.300377   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "65321  0.006969  0.077732  0.344165  0.000000  0.000536  0.000000  0.003753   \n",
       "65322  0.194071  0.892962  0.386950  0.043458  0.000298  0.000298  0.114299   \n",
       "65323  0.292853  0.722370  0.624752  0.028700  0.000195  0.000195  0.025185   \n",
       "65324  0.137409  0.626483  0.751780  0.091049  0.000418  0.000418  0.121120   \n",
       "65325  0.186527  0.596705  0.550526  0.024448  0.000905  0.000000  0.069721   \n",
       "\n",
       "             cz        ni       erl       erc        lt        hc   pr  \\\n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "1      0.000000  0.002091  0.030092  0.004120  0.000000  0.003137  0.0   \n",
       "2      0.000000  0.000898  0.009073  0.000269  0.000000  0.002246  0.0   \n",
       "3      0.002653  0.000000  0.002069  0.000159  0.000000  0.000000  0.0   \n",
       "4      0.000000  0.000000  0.046155  0.000000  0.002154  0.000000  0.0   \n",
       "...         ...       ...       ...       ...       ...       ...  ...   \n",
       "65321  0.000247  0.000000  0.007650  0.000311  0.000000  0.000041  0.0   \n",
       "65322  0.000000  0.000116  0.002536  0.000039  0.000000  0.000480  0.0   \n",
       "65323  0.000000  0.000022  0.001833  0.000061  0.000141  0.000000  0.0   \n",
       "65324  0.000023  0.000000  0.002652  0.000109  0.000093  0.000209  0.0   \n",
       "65325  0.000000  0.000302  0.023135  0.000480  0.000201  0.000201  0.0   \n",
       "\n",
       "             fo        cs        pi  \n",
       "0      0.000000  0.000333  0.000285  \n",
       "1      0.000000  0.000433  0.481838  \n",
       "2      0.000050  0.000514  0.039140  \n",
       "3      0.000000  0.002653  0.015543  \n",
       "4      0.000000  0.000971  0.000407  \n",
       "...         ...       ...       ...  \n",
       "65321  0.000000  0.000103  0.935621  \n",
       "65322  0.000000  0.000051  0.016261  \n",
       "65323  0.000011  0.000012  0.025342  \n",
       "65324  0.000000  0.000043  0.022304  \n",
       "65325  0.000151  0.000016  0.547793  \n",
       "\n",
       "[65326 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize \n",
    "norm_x = preprocessing.normalize(data_x)\n",
    "norm_x = pd.DataFrame(norm_x, columns=data_x.columns)\n",
    "\n",
    "norm_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd? Could implement a PCA for dimension reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a class for logistic regression\n",
    "\n",
    "\"\"\"\n",
    "In our logistic regression model, there are several parameters need to be pre-defined:\n",
    "    1. gamma, learning rate\n",
    "    2. max_iters, the iteration number for the gradient descent\n",
    "    3. data_x, the training dataset\n",
    "    4. data_y, the prediction outcome\n",
    "\"\"\"\n",
    "\n",
    "class logisticRegression:\n",
    "\n",
    "    def __init__(self, theta, gamma = 0.0001, max_iters = 1000):\n",
    "        self.gamma = gamma\n",
    "        self.max_iters = max_iters\n",
    "        self.theta = theta\n",
    "        self.grad = None\n",
    "    \n",
    "    # the objective function, y_hat = the prediction results from logistic regression\n",
    "    def objective_func(self, data_x, data_y):\n",
    "        data_x_yhat = data_x\n",
    "        data_x_yhat[\"y_hat\"] = np.ones(len(data_y.index))\n",
    "        \n",
    "        # gradient descent\n",
    "        grad = []\n",
    "        t = 0\n",
    "        gradnorm = np.inf\n",
    "        while gradnorm >= 0.001 and t <= self.max_iters:\n",
    "            y_hat = np.matmul(data_x_yhat, self.theta)\n",
    "            # p_logistic = 1/(1 + np.exp(-1*y_hat))\n",
    "            # c_ys_theta = -1 * data_y * np.log(p_logistic) - (1-data_y) * np.log(1-p_logistic)\n",
    "\n",
    "            # The gradient descent was defined in the following two lines of codes\n",
    "            gradient = np.matmul(-(np.array(data_y).flatten() - y_hat).T, np.array(data_x_yhat))\n",
    "            gradient_loss = gradient.flatten()\n",
    "            gt = gradient_loss\n",
    "            self.theta = self.theta - self.gamma*gt\n",
    "            gradnorm = max(abs(gt))\n",
    "            t += 1\n",
    "            #print(f\"Iternation: {t}; gradnorm = {gradnorm}\")\n",
    "            grad.append(gradnorm)\n",
    "        return self.theta, grad\n",
    "    def _sigmoid(self, x):\n",
    "        return (1/(1+np.exp(-x)))\n",
    "\n",
    "    def fitting(self, data_x, data_y):\n",
    "        data_x_y_hat = data_x\n",
    "        data_x_y_hat[\"y_hat\"] = np.ones(len(data_y.index))\n",
    "        y_hat = self._sigmoid(np.matmul(data_x_y_hat, self.theta))\n",
    "        y_hat_binary = [1 if i>0.5 else 0 for i in y_hat]\n",
    "        return y_hat_binary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training process\n",
    "start = time.time()\n",
    "# initiate the theta\n",
    "init_theta = np.zeros(len(df_data.columns))\n",
    "# find the values\n",
    "model = logisticRegression(theta = init_theta, gamma = 0.00001, max_iters=1000)\n",
    "thetas, grad = model.objective_func(norm_x, data_y)\n",
    "y_hat_all = model.fitting(norm_x, data_y)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization the gradient descent\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "axes = fig.add_subplot(111)\n",
    "axes.plot(grad)\n",
    "axes.set_xlabel(\"iteration\")\n",
    "axes.set_ylabel(\"gradnorm\")\n",
    "plt.title(\"Gradient Descent of Model Training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Logistic regression is 0.49689250834277315, spending 5.581228017807007s\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    accuracy = np.sum(np.equal(y, y_hat))/len(y)\n",
    "    return accuracy\n",
    "\n",
    "print(f\"The accuracy of the Logistic regression is {accuracy(np.array(data_y.values.tolist()).flatten(), np.array(y_hat_all))}, spending {end-start}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    norm_x, data_y, test_size = .3, random_state=42,\n",
    "    stratify = data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training process with training data\n",
    "start = time.time()\n",
    "# initiate the theta\n",
    "init_theta = np.zeros(len(df_data.columns))\n",
    "# find the values\n",
    "model_train = logisticRegression(theta = init_theta, gamma = 0.00001, max_iters=1000)\n",
    "thetas, grad = model_train.objective_func(x_train, y_train)\n",
    "y_hat_train = model_train.fitting(x_train, y_train)\n",
    "y_hat_test = model_train.fitting(x_test, y_test)\n",
    "\n",
    "end = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea5591b36d78a7686147eb4a3c93c10873566661964c9a335a9ca86597ad7498"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
